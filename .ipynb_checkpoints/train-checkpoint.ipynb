{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from data_processing import LoadData\n",
    "from model import *\n",
    "import syft as sy\n",
    "import copy\n",
    "hook = sy.TorchHook(torch)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    \n",
    "    dataset = pd.read_csv('PeMS/PeMS04.csv')\n",
    "    dataset_size = len(dataset)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split1 = int(np.floor(0.2 * dataset_size)) \n",
    "    split2 = int(np.floor(0.4 * dataset_size)) \n",
    "    split3 = int(np.floor(0.6 * dataset_size)) \n",
    "    split4 = int(np.floor(0.75 * dataset_size)) \n",
    "    split5 = int(np.floor(0.90 * dataset_size)) \n",
    "    bobs_indices, alices_indices, harrys_indices, jacks_indices, miks_indices, olivers_indices = indices[:split1], indices[split1:split2], indices[split2:split3], indices[split3:split4], indices[split4:split5], indices[split5:]\n",
    "\n",
    "    bobs_sampler = SubsetRandomSampler(bobs_indices)\n",
    "    alices_sampler = SubsetRandomSampler(alices_indices)\n",
    "    harrys_sampler = SubsetRandomSampler(harrys_indices)\n",
    "    jacks_sampler = SubsetRandomSampler(jacks_indices)\n",
    "    miks_sampler = SubsetRandomSampler(miks_indices)\n",
    "    olivers_sampler = SubsetRandomSampler(olivers_indices)\n",
    "        \n",
    "    train_data = LoadData(data_path=[\"PeMS/PeMS04.csv\", \"PeMS/PeMS04.npz\"], num_nodes=307, divide_days=[45, 14],\n",
    "                              time_interval=5, history_length=6,\n",
    "                              train_mode=\"train\")\n",
    "\n",
    "\n",
    "    bobs_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=bobs_sampler)\n",
    "    alices_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=alices_sampler)\n",
    "    harrys_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=harrys_sampler)\n",
    "    jacks_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=jacks_sampler)\n",
    "    miks_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=miks_sampler)\n",
    "    olivers_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=olivers_sampler)\n",
    "    \n",
    "#     bob alice harry jack    \n",
    "#     # Loading Dataset\n",
    "#     train_data = LoadData(data_path=[\"PeMS_04/PeMS04.csv\", \"PeMS_04/PeMS04.npz\"], num_nodes=307, divide_days=[45, 14],\n",
    "#                           time_interval=5, history_length=6,\n",
    "#                           train_mode=\"train\")\n",
    "\n",
    "#     train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=32)\n",
    "#....................................................\n",
    "#     test_data = LoadData(data_path=[\"PeMS_04/PeMS04.csv\", \"PeMS_04/PeMS04.npz\"], num_nodes=307, divide_days=[45, 14],\n",
    "#                          time_interval=5, history_length=6,\n",
    "#                          train_mode=\"test\")\n",
    "\n",
    "#     test_loader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=32)\n",
    "    \n",
    "#     for data in train_loader: \n",
    "#         print(data)\n",
    "\n",
    "    #model = GCN(in_c=6 , hid_c=6 ,out_c=1)\n",
    "    #ChebNet(in_c=6, hid_c=32, out_c=1, K=2)\n",
    "    #GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    bobs_model = ChebNet(in_c=6, hid_c=32, out_c=1, K=2)     # 2阶切比雪夫模型    \n",
    "    bobs_model = bobs_model.to(device)\n",
    "    \n",
    "    alices_model = ChebNet(in_c=6, hid_c=32, out_c=1, K=2)      # 2阶切比雪夫模型\n",
    "    alices_model = alices_model.to(device)\n",
    "    \n",
    "    harrys_model = ChebNet(in_c=6, hid_c=32, out_c=1, K=2)\n",
    "    harrys_model = harrys_model.to(device)\n",
    "    \n",
    "    jacks_model = ChebNet(in_c=6, hid_c=32, out_c=1, K=2)\n",
    "    jacks_model = jacks_model.to(device)\n",
    "    \n",
    "    miks_model = ChebNet(in_c=6, hid_c=32, out_c=1, K=2)\n",
    "    miks_model = miks_model.to(device)\n",
    "    \n",
    "    olivers_model = ChebNet(in_c=6, hid_c=32, out_c=1, K=2)\n",
    "    olivers_model = olivers_model.to(device)\n",
    "    \n",
    "    #new\n",
    "    bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "    alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "    harry = sy.VirtualWorker(hook, id=\"harry\")\n",
    "    jack = sy.VirtualWorker(hook, id=\"jack\")\n",
    "    mik = sy.VirtualWorker(hook, id=\"mik\")\n",
    "    oliver = sy.VirtualWorker(hook, id=\"oliver\")\n",
    "    secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
    "\n",
    "    #new\n",
    "#     bobs_model = model.copy().send(bob)\n",
    "#     alices_model = model.copy().send(alice)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    #new\n",
    "    bobs_opt = optim.Adam(params=bobs_model.parameters())\n",
    "    alices_opt = optim.Adam(params=alices_model.parameters())\n",
    "    harrys_opt = optim.Adam(params=harrys_model.parameters())\n",
    "    jacks_opt = optim.Adam(params=jacks_model.parameters())\n",
    "    miks_opt = optim.Adam(params = miks_model.parameters())\n",
    "    olivers_opt = optim.Adam(params = olivers_model.parameters())\n",
    "    \n",
    "    \n",
    "    # Train model\n",
    "    Epoch = 8\n",
    "\n",
    "    bobs_model.train()\n",
    "    alices_model.train()\n",
    "    harrys_model.train()\n",
    "    jacks_model.train()\n",
    "    miks_model.train()\n",
    "    olivers_model.train()\n",
    "    \n",
    "    for epoch in range(Epoch):\n",
    "    \t#new\n",
    "        epoch_loss_bob = 0.0\n",
    "        epoch_loss_alice = 0.0\n",
    "        epoch_loss_harry = 0.0\n",
    "        epoch_loss_jack = 0.0\n",
    "        epoch_loss_mik = 0.0\n",
    "        epoch_loss_oliver = 0.0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for data in bobs_loader:  # [\"graph\": [B, N, N] , \"flow_x\": [B, N, H, D], \"flow_y\": [B, N, 1, D]]\n",
    "            bobs_model.zero_grad()\n",
    "            predict_value = bobs_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_bob += loss.item()\n",
    "            loss.backward()\n",
    "            bobs_opt.step()\n",
    "            \n",
    "        for data in alices_loader:\n",
    "            alices_model.zero_grad()\n",
    "            predict_value = alices_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_alice += loss.item()\n",
    "            loss.backward()\n",
    "            alices_opt.step()\n",
    "            \n",
    "        for data in harrys_loader:\n",
    "            harrys_model.zero_grad()\n",
    "            predict_value = harrys_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_harry += loss.item()\n",
    "            loss.backward()\n",
    "            harrys_opt.step()\n",
    "            \n",
    "        for data in jacks_loader:\n",
    "            jacks_model.zero_grad()\n",
    "            predict_value = jacks_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_jack += loss.item()\n",
    "            loss.backward()\n",
    "            jacks_opt.step()    \n",
    "            \n",
    "        for data in miks_loader:\n",
    "            miks_model.zero_grad()\n",
    "            predict_value = miks_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_mik += loss.item()\n",
    "            loss.backward()\n",
    "            miks_opt.step()\n",
    "            \n",
    "        for data in olivers_loader:\n",
    "            olivers_model.zero_grad()\n",
    "            predict_value = olivers_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_oliver += loss.item()\n",
    "            loss.backward()\n",
    "            olivers_opt.step()        \n",
    "            \n",
    "        end_time = time.time()\n",
    "\n",
    "        print(\"Epoch: {:04d}, Loss Bob: {:02.4f}, Loss Alice: {:02.4f}, Loss Harry: {:02.4f}, Loss Jack: {:02.4f}, Loss Mik: {:02.4f}, Loss Oliver: {:02.4f}, Time: {:02.2f} mins\".format(epoch, 1000 * epoch_loss_bob / len(train_data), 1000 * epoch_loss_alice / len(train_data), 1000 * epoch_loss_harry / len(train_data), 1000 * epoch_loss_jack / len(train_data), 1000 * epoch_loss_mik / len(train_data), 1000 * epoch_loss_oliver / len(train_data),\n",
    "                                                                          (end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
